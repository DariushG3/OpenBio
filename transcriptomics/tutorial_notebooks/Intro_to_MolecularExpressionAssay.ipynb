{"metadata": {"language_info": {"name": "python", "version": "3.6.5", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}, "kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}}, "nbformat_minor": 5, "nbformat": 4, "cells": [{"cell_type": "markdown", "source": "# Introduction to working with a MolecularExpressionAssay", "metadata": {}}, {"cell_type": "markdown", "source": "This notebook shows how to:\n\n1. Parse MolecularExpressionAssay metadata from a Dataset\n2. Access molecular expression data from a Molecular Expression Dataset", "metadata": {}}, {"cell_type": "markdown", "source": "## 1: Parse MolecularExpressionAssay metadata from a Dataset", "metadata": {}}, {"cell_type": "markdown", "source": "#### From the JupyterLab instance, select a Python3 kernel and import dxdata", "metadata": {}}, {"cell_type": "code", "source": "import dxdata", "metadata": {"trusted": true}, "execution_count": 2, "outputs": []}, {"cell_type": "markdown", "source": "#### Load Dataset (or Cohort)", "metadata": {}}, {"cell_type": "code", "source": "molecular_expression_dataset = dxdata.load_dataset(id=\"record-G7y66Vj0GjvK7xbp4Xg2Zjy5\")", "metadata": {"trusted": true}, "execution_count": 10, "outputs": []}, {"cell_type": "code", "source": "molecular_expression_dataset.__dict__", "metadata": {"trusted": true}, "execution_count": 11, "outputs": [{"execution_count": 11, "output_type": "execute_result", "data": {"text/plain": "{'entities': [<Entity \"sample\">],\n 'edges': [<dxdata.dataset.dataset.Edge at 0x7fc259133a90>,\n  <dxdata.dataset.dataset.Edge at 0x7fc259126c18>],\n 'entities_by_name': OrderedDict([('sample', <Entity \"sample\">)]),\n 'primary_entity': <Entity \"sample\">,\n 'dashboards': OrderedDict(),\n 'primary_dashboard': None,\n 'annotations': [],\n 'assays': DxOrderedDict([('my_expression_project',\n                 <dxdata.dataset.assay.MolecularExpressionAssay at 0x7fc259125ac8>)])}"}, "metadata": {}}]}, {"cell_type": "code", "source": "molecular_expression_dataset.assays", "metadata": {"trusted": true}, "execution_count": 15, "outputs": [{"execution_count": 15, "output_type": "execute_result", "data": {"text/plain": "DxOrderedDict([('my_expression_project',\n                <dxdata.dataset.assay.MolecularExpressionAssay at 0x7fc259125ac8>)])"}, "metadata": {}}]}, {"cell_type": "markdown", "source": "#### Select your desired assay and parse the Assay class for desired metadata", "metadata": {}}, {"cell_type": "code", "source": "assay = molecular_expression_dataset.assays[\"my_expression_project\"]\nassay.entities", "metadata": {"trusted": true}, "execution_count": 12, "outputs": [{"execution_count": 12, "output_type": "execute_result", "data": {"text/plain": "OrderedDefaultDict([('expr_annotation', <Entity \"expr_annotation\">),\n                    ('expression', <Entity \"expression\">)])"}, "metadata": {}}]}, {"cell_type": "markdown", "source": "## 2: Access molecular expression data from a Molecular Expression Dataset", "metadata": {}}, {"cell_type": "markdown", "source": "#### A Spark-enabled JupyterLab instance may be used to access, analyze and/or extract data, as referenced in a Molecular Expression Assay Loader Dataset. From the JupyterLab instance, select a Python3 kernel and set up the environment.", "metadata": {}}, {"cell_type": "code", "source": "import dxdata\nimport pyspark\n\n# Initiate Spark\nsc = pyspark.SparkContext()\nspark = pyspark.sql.SparkSession(sc)", "metadata": {"trusted": true}, "execution_count": 5, "outputs": []}, {"cell_type": "markdown", "source": "#### Extract assay information and run query.", "metadata": {}}, {"cell_type": "code", "source": "# Specify dataset and assay\ndataset = dxdata.load_dataset(id=\"record-G7y66Vj0GjvK7xbp4Xg2Zjy5\")\nassay = dataset.assays[\"my_expression_project\"]\n\n# Build SQL\ntable = \"expression\"\ndatabase = assay.entities[table].database_name\nsql = f\"SELECT * from {database}.{table}\"\n\n# Build Spark DataFrame from SQL\nsdf = spark.sql(sql)\nsdf.show(10)", "metadata": {"trusted": true}, "execution_count": 14, "outputs": [{"name": "stdout", "text": "+---------------+---------+-----+\n|     feature_id|sample_id|value|\n+---------------+---------+-----+\n|ENST00000346162| sample_2|   85|\n|ENST00000438810| sample_1|   68|\n|ENST00000305531| sample_2|   88|\n|ENST00000427231| sample_3|   27|\n|ENST00000427970| sample_3|    4|\n|ENST00000290037| sample_3|   21|\n|ENST00000358472| sample_1|    5|\n|ENST00000398738| sample_1|    8|\n|ENST00000421624| sample_1|   90|\n|ENST00000397381| sample_2|   24|\n+---------------+---------+-----+\nonly showing top 10 rows\n\n", "output_type": "stream"}]}, {"cell_type": "markdown", "source": "#### A Spark DataFrame may be written to a file, further analyzed using Spark  (or Koalas), or read into memory and analyzed using Pandas.", "metadata": {}}]}